{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Bhumika\n",
        "\n",
        "\n",
        "completing day 2 of machine learning\n",
        "\n"
      ],
      "metadata": {
        "id": "Papku5I3N3L-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9FaSM8xmAI2q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"link\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "6j5KN_MFAoJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**load csv using** **URL**"
      ],
      "metadata": {
        "id": "l3Bf2XrmFiyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import StringIO\n",
        "#server se loading\n",
        "url =\"github link\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0\"  # Example header; modify as needed\n",
        "}\n",
        "req= requests.get(url,headers= headers)\n",
        "data= StringIO(req.text)\n",
        "\n",
        "pd.read_csv(data)"
      ],
      "metadata": {
        "id": "8eadiMdzCKgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HANDLE TAB SEPERATED FILES**"
      ],
      "metadata": {
        "id": "dFlck3NzCW7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sep parameter\n",
        "df= pd.read_csv(\"link\" , sep='\\t')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "BEyTLc9ACLXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Index-col** **parameter**"
      ],
      "metadata": {
        "id": "YI_DHaauE6Ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, index_col=0)  # First column as index\n"
      ],
      "metadata": {
        "id": "uIioH8MYDBVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Headers**"
      ],
      "metadata": {
        "id": "eggwVcS9FIsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, header=0)  # First row as headers\n",
        "df = pd.read_csv(data, header=None)  # No headers, treats all rows as data\n"
      ],
      "metadata": {
        "id": "SfuURZFiDFlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**use-cols** **parameter**"
      ],
      "metadata": {
        "id": "DgKf_7okFN1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, usecols=[\"Name\", \"Age\"])  # Load only \"Name\" and \"Age\"\n",
        "df = pd.read_csv(data, usecols=[0, 2])  # Load only the 1st and 3rd columns\n"
      ],
      "metadata": {
        "id": "P-cagiAyEWm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**squeeze** **parameter**"
      ],
      "metadata": {
        "id": "PDiX9HfZFTVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, usecols=[\"Age\"], squeeze=True)  # Returns a Series instead of a DataFrame\n"
      ],
      "metadata": {
        "id": "LjrJPETREWhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**skiprows** **parameter**"
      ],
      "metadata": {
        "id": "g5QwmnYkFaCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, skiprows=3)  # Skip the first 3 rows\n",
        "#df = pd.read_csv(data, skiprows=[1, 3, 5])  # Skip rows 1, 3, and 5\n"
      ],
      "metadata": {
        "id": "wT-Cs71IEoow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nrows Parameter**"
      ],
      "metadata": {
        "id": "L05-rUgGFf8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, nrows=100)  # Read only the first 5 rows\n"
      ],
      "metadata": {
        "id": "_y1dx6BYEoR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**encoding Parameter**\n",
        "Handles files with different text encodings (default is 'utf-8')."
      ],
      "metadata": {
        "id": "27YT0sGTFw4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, encoding=\"latin1\")  # Use 'latin1' for special characters\n",
        "df = pd.read_csv(data, encoding=\"ISO-8859-1\")  # Another encoding option\n"
      ],
      "metadata": {
        "id": "UUdPM7nyGECr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**skip bad lines**"
      ],
      "metadata": {
        "id": "deIU3vekGTDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, on_bad_lines=\"skip\")  # Skip bad rows\n"
      ],
      "metadata": {
        "id": "guLrgFsaGSqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**dtype** **Parameter (Handling Data Types)**"
      ],
      "metadata": {
        "id": "GAQyUvGfG7-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, dtype={\"Age\": int, \"Salary\": float})  # Force \"Age\" as int and \"Salary\" as float\n"
      ],
      "metadata": {
        "id": "K5cTJcQyGSRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parse dates parameters**"
      ],
      "metadata": {
        "id": "H0qO20xoK7r5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, parse_dates=[\"Start Date\", \"End Date\"])\n"
      ],
      "metadata": {
        "id": "oqXIBRxcJLSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converters**"
      ],
      "metadata": {
        "id": "V8gqxqoCKtye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, converters={\"Age\": lambda x: int(x) * 2})\n",
        "# Doubles the values in the \"Age\" column\n"
      ],
      "metadata": {
        "id": "sgemlWXfJUZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, converters={\"Name\": lambda x: x.lower()})\n"
      ],
      "metadata": {
        "id": "xmufkxsJKsYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, converters={\"Salary\": lambda x: float(x) if x else 0.0})\n"
      ],
      "metadata": {
        "id": "OoYcT5kMKsVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "df = pd.read_csv(data, converters={\"Date\": lambda x: datetime.strptime(x, \"%d-%m-%Y\")})\n"
      ],
      "metadata": {
        "id": "r9QQU16YKsSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\n",
        "    data,\n",
        "    converters={\n",
        "        \"Price\": lambda x: float(x.replace(\"$\", \"\").replace(\",\", \"\")),  # Remove \"$\" and convert to float\n",
        "        \"Category\": lambda x: x.strip().upper(),  # Remove spaces and convert to uppercase\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "0fiIBezsKsPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Na-values parameter**"
      ],
      "metadata": {
        "id": "sW52Dh80Mk6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data, na_values=[\"N/A\", \"NULL\", \"Missing\", \"NA\", \"\"])\n",
        "# Treats these as NaN: \"N/A\", \"NULL\", \"Missing\", \"NA\", and empty strings\n"
      ],
      "metadata": {
        "id": "yqMI3aNlKsL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**load huge data in chunks**"
      ],
      "metadata": {
        "id": "gZa2aPoPMqMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 10000  # Read 10,000 rows at a time\n",
        "\n",
        "for chunk in pd.read_csv(\"large_file.csv\", chunksize=chunk_size):\n",
        "    print(chunk.head())  # Process each chunk separately\n"
      ],
      "metadata": {
        "id": "zu2unHIRKsIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = []\n",
        "for chunk in pd.read_csv(\"large_file.csv\", chunksize=5000):\n",
        "    chunk[\"New_Column\"] = chunk[\"Salary\"] * 1.1  # Example transformation\n",
        "    chunks.append(chunk)\n",
        "\n",
        "df = pd.concat(chunks)  # Merge all chunks into a final DataFrame\n"
      ],
      "metadata": {
        "id": "ViSo_4baM312"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in pd.read_csv(\"large_file.csv\", chunksize=10000):\n",
        "    filtered_chunk = chunk[chunk[\"Age\"] > 30]  # Process only Age > 30\n",
        "    print(filtered_chunk.shape)\n"
      ],
      "metadata": {
        "id": "OAfk0HgBM42u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in pd.read_csv(\"large_file.csv\", chunksize=20000):\n",
        "    chunk.to_csv(\"processed_data.csv\", mode=\"a\", index=False, header=False)  #mode=\"a\" → Append mode\n",
        "#f you don’t want to keep everything in memory, write to a new CSV file chunk by chunk:"
      ],
      "metadata": {
        "id": "XuVFNJA8M4tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_results = []\n",
        "\n",
        "for i, chunk in enumerate(pd.read_csv(input_file, chunksize=chunk_size)):\n",
        "    salary_avg = chunk[\"Salary\"].mean()\n",
        "    chunk_results.append([i+1, salary_avg])\n",
        "\n",
        "df = pd.DataFrame(chunk_results, columns=[\"Chunk_Number\", \"Salary_Average\"])\n",
        "df.to_csv(\"processed.csv\", index=False)  # Save final DataFrame\n"
      ],
      "metadata": {
        "id": "l3rU4PM2NyIM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}